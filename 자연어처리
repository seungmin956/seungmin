★ 자연어 처리

#토큰화-> 정제-> 추출-> 인코딩-> 패딩

# pip install nltk
import nltk
# print(nltk.__version__)

#단어 토큰화 
from nltk.tokenize import TreebankWordTokenizer
tokenizer=TreebankWordTokenizer()
text="Model-based reinforcement learning don't need a value function for the policy."
# print(tokenizer.tokenize(text))

#문장 토큰화

#한국어 토큰화의 어려움

#정제-> 대.소문자/ 출현 횟수가 적은 단어/ 길이가 짧은 단어, 지시대명사,관사의제거

#추출 (어간 추출 vs 표제어 추출) 표제어 추출은 품사의 정보를 포함하고 있다.

#불용어
import nltk
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

input_sentence="We should all study hard for the exam."
stop_words=set(stopwords.words('english'))
word_tokens=word_tokenize(input_sentence)
print(stop_words)
print(word_tokens)

result=[]
for w in word_tokens:
    if w not in stop_words:
        result.append(w)

print(result)
